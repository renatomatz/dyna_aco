"""Define World classes, which generally handle information relevant to the
algorithm, logging/history information generated by the algorithm and the
execution details of the algorithm.

World classes serve two main purposes:
1. Store data about the world, that is, information that is available to every
agent, but subject to each agent's specific interpreptations. This includes
base beliefs as well as pheromones left behind by ants. How these change,
however, is dictated by other objects, whereas the World class only stores
their values. Note that this information includes ant generators themselves,
random draw generators and functions to evaluate these draws.
2. Orchestrate the execution of the algorithm, which is highly dependent on the
overall optimization at hand, but generally involves: generating ants; handling
equivalent parallel and sequential versions of the algorithm; handling
information generated by the algorithm.

Other functionalities, such as plotting and profiling, can be implemented,
though these will generally fall within the second purpose of these classes. A
distributed version of the World class that immitates the first purpose is
available in the <ant> module and is called <AntHandler.DummyWorld>.

Unlike <Ant> and <Model> objects, there shall only be one World per execution
of the optimization. While heterogeneity can be modeled within the world's
mechanics, it shall not be performed with multiple worlds.
"""

import time

from math import ceil
from types import SimpleNamespace
from inspect import ismodule

import numpy as np

from mpi4py import MPI
from numba import cuda
from numba.cuda.random import create_xoroshiro128p_states

from log_helpers import LoggingVisitor
from utils import assert_type, _NamespaceHandler


class Optimizer(_NamespaceHandler):
    """Base Optimizer class.

    Defines data common to all descending classes as well as methods which use
    this data in a model-agnostic fashion.
    """
    def __init__(self, model, logger=None):

        super().__init__()

        self.model = model
        self.logger = logger

        # Internal stats
        self.fit_time = 0
        self.iters = 0

    def __str__(self):
        string = f"{type(self).__name__}\n"
        string += f"{type(self.model).__name__}\n"
        return string

    def fit(self, iters=500, n_procs=1):
        raise NotImplementedError()


class TabularQOptimizer(Optimizer):
    """World which generates and handles information for a single type of Ant.

    This world provides functionality for a single type of ant and the
    information they require.

    Note:
        This does not mean that and behaviour and parameters are heterogeneous,
        it only means that only one ant generator is used to "birth" new ants.
        Heterogeneity can still be modeled by this generator, which can vary
        ant parameters in whichever way is necessary.
    """

    def __init__(self, model, n_births, evaporation_rate=0.0,
                 logger=None):

        super().__init__(model, logger=logger)

        self.n_births = n_births
        self.evaporation_rate = evaporation_rate
        self.logger = logger if logger is not None else LoggingVisitor()

        self.ant_gen = None

        self._data = SimpleNamespace()
        self.req_vars += ["q_beliefs", "q_pheromones"]

    def __str__(self):
        string = super().__str__()
        string += f"\nNumber of Births:\t\t\t\t{self.n_births}"
        return string

    def _check_q(self, q):
        assert_type(q, np.ndarray, "Q values")
        if len(q.shape) != 2:
            ValueError("Q values should be two-dimensional")

    @property
    def q_beliefs(self):
        return self._data.q_beliefs

    @q_beliefs.setter
    def q_beliefs(self, q):
        self._check_q(q)
        self.set_data_attr("q_beliefs", q)

    @property
    def q_pheromones(self):
        return self._data.q_pheromones

    @q_pheromones.setter
    def q_pheromones(self, q):
        self._check_q(q)
        self.set_data_attr("q_pheromones", q)

    def reset_pheromones(self):
        self.q_pheromones = self.q_beliefs.copy()

    def evaporation(self):
        """Shorten the gap between beliefs and pheromones.
        """
        beliefs_update = ((self.q_pheromones - self.q_beliefs) *
                          (self.evaporation_rate/2))
        pheromones_update = ((self.q_beliefs - self.q_pheromones) *
                             (self.evaporation_rate/2))

        self.q_beliefs += beliefs_update
        self.q_pheromones += pheromones_update

    def fit(self, iters=500, n_procs=1):
        """Fit the model in a sequential fashion.

        This is called in case one processor is specified in the main <fit>
        method.

        Note:
            This is usually enough for most ants with little computation
            needed to make a decision.
        """
        self.check_req_vars()

        start = time.time()
        for _ in range(iters):

            ants = list()
            for _ in range(self.n_births):
                ant = next(self.ant_gen)
                ant.play(self._data, self.model)
                ants.append(ant)

            old_pher = self.q_pheromones
            new_pher = np.zeros_like(old_pher)
            rho_tot = np.zeros_like(old_pher)

            for ant in ants:
                ant.update(old_pher, new_pher, rho_tot)
                self.logger.get_data(ant)

            rho_tot[rho_tot == 0] = 1
            old_pher += (new_pher/rho_tot)

            self.evaporation()

            self.fit_time += round(time.time() - start)
            self.iters += 1

            self.logger.get_data(self)
            self.logger()


class MPITabularQOptimizer(TabularQOptimizer):

    def __init__(self, model, n_births, evaporation_rate=0.0,
                 logger=None):

        super().__init__(model, n_births, evaporation_rate=evaporation_rate,
                         logger=logger)

        self.comm = MPI.COMM_WORLD
        self.me = self.comm.Get_rank()
        self.p = self.comm.Get_size()

        self.r = self.n_births % self.p
        self.n = (ceil(self.n_births/self.p)
                  - int((self.r > 0) and (self.me > self.r)))

    def fit(self, iters=500, n_procs=1):

        self.check_req_vars()

        for _ in range(iters):

            start = time.time()

            ants = self._gen_ant_list()
            for ant in ants:
                ant.play(self._data, self.model)

            old_pher = self.q_pheromones
            new_pher = np.zeros_like(old_pher)
            rho_tot = np.zeros_like(old_pher)

            for ant in ants:
                ant.update(old_pher, new_pher, rho_tot)

            red_mat = self.comm.allreduce(np.array([new_pher, rho_tot]),
                                          MPI.SUM)

            new_pher = red_mat[0]
            rho_tot = red_mat[1]

            rho_tot[rho_tot == 0] = 1
            old_pher += (new_pher/rho_tot)

            self.evaporation()

            self.fit_time += round(time.time() - start)
            self.iters += 1

            # logging
            if not self.logger.is_empty():
                if self.me == 0:
                    # log master info
                    for ant in ants:
                        self.logger.get_data(ant)
                    self.logger.get_data(self)
                    self.logger()

                    # log child info
                    for pidx in range(1, self.p):
                        ants = self.comm.recv(source=pidx, tag=2)
                        for ant in ants:
                            self.logger.get_data(ant)
                else:
                    self.comm.send(ants, dest=0, tag=2)

    def _gen_ant_list(self):
        return [next(self.ant_gen) for _ in range(self.n)]


class CUDATabularQOptimizer(TabularQOptimizer):

    def __init__(self, model, n_births, evaporation_rate=0.0,
                 logger=None):

        # CUDA kernels shall be referenced by name.
        if not isinstance(model, str):
            model = type(model).__name__

        super().__init__(model, n_births, evaporation_rate=evaporation_rate,
                         logger=logger)

        self.mods = dict()

    def _check_q(self, q):
        super()._check_q(q)
        if (self.n_births % np.prod(q.shape != 0)):
            raise ValueError("The state-action combinations must be a "
                             "multiple of the number of births. Either change "
                             "the value of n_births or select a model with "
                             "different dimensions.")

    def load_module(self, mod_name, source, code=False):
        if not ismodule(source):
            raise TypeError("jitted source should be a module")
        self.mods[mod_name] = source

    def mod_kernel(self, mod_name, func_name):
        blk_dims = self.q_pheromones.shape
        n_blocks = (self.n_births // np.prod(blk_dims), )

        # use func[griddim, blockdim, stream, sharedmem]
        # and np.dtype(wp).itemsize
        # and numba.cuda.default_stream()

        return getattr(self.mods[mod_name], func_name)[n_blocks,
                                                       blk_dims]

        # TODO: Make dynamic shared memory work
        # threads_per_block = np.prod(blk_dims)
        # n_blocks = (self.n_births // threads_per_block,)

        # # use func[griddim, blockdim, stream, sharedmem]
        # # and np.dtype(wp).itemsize
        # # and numba.cuda.default_stream()

        # stream = cuda.default_stream()
        # shared_size = threads_per_block*np.dtype(np.float32).itemsize
        # return getattr(self.mods[mod_name], func_name)[n_blocks,
        #                                                blk_dims,
        #                                                stream,
        #                                                shared_size]

    def fit(self, iters=500, n_procs=1):
        self.check_req_vars()

        start = time.time()
        for _ in range(iters):

            ant = next(self.ant_gen)

            old_pher = cuda.to_device(self.q_pheromones)
            q_vals = ant.adjust_beliefs(self.q_beliefs,
                                        self.q_pheromones)
            q_vals = cuda.to_device(q_vals)

            gamma = ant.gamma

            new_pher = cuda.to_device(np.zeros_like(old_pher))
            rho_tot = cuda.to_device(np.zeros_like(old_pher))
            tot_util = cuda.to_device(np.zeros_like(old_pher))

            rng_states = create_xoroshiro128p_states(self.n_births,
                                                     seed=42)

            self.mod_kernel("ant", self.model)(
                    old_pher, q_vals,
                    gamma,
                    new_pher, rho_tot, tot_util,
                    rng_states
            )

            new_pher = new_pher.copy_to_host()
            rho_tot = rho_tot.copy_to_host()
            tot_util = tot_util.copy_to_host()

            tot_util = tot_util.sum() / self.n_births
            self.logger.get_data(tot_util, tag="tot_util")

            rho_tot[rho_tot == 0] = 1
            self.q_pheromones = self.q_pheromones + (new_pher/rho_tot)

            self.evaporation()

            self.fit_time += round(time.time() - start)
            self.iters += 1

            self.logger.get_data(self)
            self.logger()
